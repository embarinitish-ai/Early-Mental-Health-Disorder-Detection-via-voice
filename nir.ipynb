{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "325a11c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading audio for 313...\n",
      "Finished Participant 313: Created 7 chunks in C:/Users/embar/OneDrive/Desktop/Nirvana/Audio Data/DiacWoz/Processed_Chunks\\313_Chunks\n",
      "Loading audio for 315...\n",
      "Finished Participant 315: Created 13 chunks in C:/Users/embar/OneDrive/Desktop/Nirvana/Audio Data/DiacWoz/Processed_Chunks\\315_Chunks\n",
      "Loading audio for 316...\n",
      "Finished Participant 316: Created 5 chunks in C:/Users/embar/OneDrive/Desktop/Nirvana/Audio Data/DiacWoz/Processed_Chunks\\316_Chunks\n",
      "Loading audio for 317...\n",
      "Finished Participant 317: Created 6 chunks in C:/Users/embar/OneDrive/Desktop/Nirvana/Audio Data/DiacWoz/Processed_Chunks\\317_Chunks\n",
      "Loading audio for 318...\n",
      "Finished Participant 318: Created 6 chunks in C:/Users/embar/OneDrive/Desktop/Nirvana/Audio Data/DiacWoz/Processed_Chunks\\318_Chunks\n",
      "Loading audio for 322...\n",
      "Finished Participant 322: Created 13 chunks in C:/Users/embar/OneDrive/Desktop/Nirvana/Audio Data/DiacWoz/Processed_Chunks\\322_Chunks\n",
      "Loading audio for 324...\n",
      "Finished Participant 324: Created 7 chunks in C:/Users/embar/OneDrive/Desktop/Nirvana/Audio Data/DiacWoz/Processed_Chunks\\324_Chunks\n",
      "Loading audio for 400...\n",
      "Finished Participant 400: Created 11 chunks in C:/Users/embar/OneDrive/Desktop/Nirvana/Audio Data/DiacWoz/Processed_Chunks\\400_Chunks\n",
      "Loading audio for 326...\n",
      "Finished Participant 326: Created 4 chunks in C:/Users/embar/OneDrive/Desktop/Nirvana/Audio Data/DiacWoz/Processed_Chunks\\326_Chunks\n",
      "Loading audio for 327...\n",
      "Finished Participant 327: Created 7 chunks in C:/Users/embar/OneDrive/Desktop/Nirvana/Audio Data/DiacWoz/Processed_Chunks\\327_Chunks\n",
      "Loading audio for 328...\n",
      "Finished Participant 328: Created 18 chunks in C:/Users/embar/OneDrive/Desktop/Nirvana/Audio Data/DiacWoz/Processed_Chunks\\328_Chunks\n",
      "Loading audio for 401...\n",
      "Finished Participant 401: Created 12 chunks in C:/Users/embar/OneDrive/Desktop/Nirvana/Audio Data/DiacWoz/Processed_Chunks\\401_Chunks\n",
      "Loading audio for 402...\n",
      "Finished Participant 402: Created 12 chunks in C:/Users/embar/OneDrive/Desktop/Nirvana/Audio Data/DiacWoz/Processed_Chunks\\402_Chunks\n",
      "Loading audio for 409...\n",
      "Finished Participant 409: Created 16 chunks in C:/Users/embar/OneDrive/Desktop/Nirvana/Audio Data/DiacWoz/Processed_Chunks\\409_Chunks\n",
      "Loading audio for 412...\n",
      "Finished Participant 412: Created 9 chunks in C:/Users/embar/OneDrive/Desktop/Nirvana/Audio Data/DiacWoz/Processed_Chunks\\412_Chunks\n",
      "Loading audio for 414...\n",
      "Finished Participant 414: Created 14 chunks in C:/Users/embar/OneDrive/Desktop/Nirvana/Audio Data/DiacWoz/Processed_Chunks\\414_Chunks\n",
      "Loading audio for 415...\n",
      "Finished Participant 415: Created 10 chunks in C:/Users/embar/OneDrive/Desktop/Nirvana/Audio Data/DiacWoz/Processed_Chunks\\415_Chunks\n",
      "Loading audio for 416...\n",
      "Finished Participant 416: Created 12 chunks in C:/Users/embar/OneDrive/Desktop/Nirvana/Audio Data/DiacWoz/Processed_Chunks\\416_Chunks\n",
      "Loading audio for 426...\n",
      "Finished Participant 426: Created 9 chunks in C:/Users/embar/OneDrive/Desktop/Nirvana/Audio Data/DiacWoz/Processed_Chunks\\426_Chunks\n",
      "Loading audio for 433...\n",
      "Finished Participant 433: Created 8 chunks in C:/Users/embar/OneDrive/Desktop/Nirvana/Audio Data/DiacWoz/Processed_Chunks\\433_Chunks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# Use 'r' before the string to handle Windows backslashes correctly\n",
    "BASE_PATH = r'C:/Users/embar/OneDrive/Desktop/Nirvana/Audio Data/DiacWoz/Raw'\n",
    "OUTPUT_BASE = r'C:/Users/embar/OneDrive/Desktop/Nirvana/Audio Data/DiacWoz/Processed_Chunks'\n",
    "\n",
    "CHUNK_DURATION = 35  # Duration in seconds\n",
    "SAMPLE_RATE = 16000  # DAIC-WOZ standard sampling rate\n",
    "\n",
    "# Create output folder if it doesn't exist\n",
    "if not os.path.exists(OUTPUT_BASE):\n",
    "    os.makedirs(OUTPUT_BASE)\n",
    "\n",
    "def process_local_participant(p_id):\n",
    "    p_folder = os.path.join(BASE_PATH, f\"{p_id}_P\")\n",
    "    audio_path = os.path.join(p_folder, f\"{p_id}_AUDIO.wav\")\n",
    "    transcript_path = os.path.join(p_folder, f\"{p_id}_TRANSCRIPT.csv\")\n",
    "\n",
    "    # Check if files exist\n",
    "    if not os.path.exists(audio_path) or not os.path.exists(transcript_path):\n",
    "        print(f\"Skipping {p_id}: Audio or Transcript missing at {p_folder}\")\n",
    "        return\n",
    "\n",
    "    # 1. Load transcript (DAIC uses tab-separated values)\n",
    "    df = pd.read_csv(transcript_path, sep='\\t')\n",
    "    \n",
    "    # 2. Filter for 'Participant' speech only\n",
    "    participant_df = df[df['speaker'] == 'Participant']\n",
    "    \n",
    "    if participant_df.empty:\n",
    "        print(f\"No participant speech found for {p_id}\")\n",
    "        return\n",
    "\n",
    "    # 3. Load raw audio\n",
    "    print(f\"Loading audio for {p_id}...\")\n",
    "    y, sr = librosa.load(audio_path, sr=SAMPLE_RATE)\n",
    "    \n",
    "    # 4. Extract and concatenate only participant voice segments\n",
    "    participant_segments = []\n",
    "    for _, row in participant_df.iterrows():\n",
    "        start_idx = int(row['start_time'] * sr)\n",
    "        stop_idx = int(row['stop_time'] * sr)\n",
    "        segment = y[start_idx:stop_idx]\n",
    "        participant_segments.append(segment)\n",
    "    \n",
    "    full_voice = np.concatenate(participant_segments)\n",
    "\n",
    "    # 5. Break the continuous voice into 35-second chunks\n",
    "    samples_per_chunk = CHUNK_DURATION * sr\n",
    "    num_chunks = len(full_voice) // samples_per_chunk\n",
    "\n",
    "    if num_chunks == 0:\n",
    "        print(f\"Participant {p_id} voice too short for a single {CHUNK_DURATION}s chunk.\")\n",
    "        return\n",
    "\n",
    "    # 6. Save chunks to separate folder for each participant\n",
    "    out_dir = os.path.join(OUTPUT_BASE, f\"{p_id}_Chunks\")\n",
    "    if not os.path.exists(out_dir): \n",
    "        os.makedirs(out_dir)\n",
    "\n",
    "    for i in range(num_chunks):\n",
    "        start = i * samples_per_chunk\n",
    "        end = start + samples_per_chunk\n",
    "        chunk = full_voice[start:end]\n",
    "        \n",
    "        chunk_name = f\"{p_id}_part_{i}.wav\"\n",
    "        save_path = os.path.join(out_dir, chunk_name)\n",
    "        sf.write(save_path, chunk, sr)\n",
    "    \n",
    "    print(f\"Finished Participant {p_id}: Created {num_chunks} chunks in {out_dir}\")\n",
    "\n",
    "# --- EXECUTION ---\n",
    "# List of IDs you have downloaded\n",
    "my_participants = ['313', '315', '316', '317', '318', '322', '324', '400', '326', '327', '328', '401','402','409','412','414','415','416','426','433']\n",
    "for pid in my_participants:\n",
    "    try:\n",
    "        process_local_participant(pid)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {pid}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd04957",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "veritasvision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
