{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "325a11c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading audio for 303...\n",
      "Finished Participant 303: Created 18 chunks in C:/Users/embar/OneDrive/Desktop/Nirvana/Audio Data/DiacWoz/Processed_Chunks\\303_Chunks\n",
      "Loading audio for 304...\n",
      "Finished Participant 304: Created 10 chunks in C:/Users/embar/OneDrive/Desktop/Nirvana/Audio Data/DiacWoz/Processed_Chunks\\304_Chunks\n",
      "Loading audio for 305...\n",
      "Finished Participant 305: Created 31 chunks in C:/Users/embar/OneDrive/Desktop/Nirvana/Audio Data/DiacWoz/Processed_Chunks\\305_Chunks\n",
      "Loading audio for 310...\n",
      "Finished Participant 310: Created 8 chunks in C:/Users/embar/OneDrive/Desktop/Nirvana/Audio Data/DiacWoz/Processed_Chunks\\310_Chunks\n",
      "Loading audio for 312...\n",
      "Finished Participant 312: Created 8 chunks in C:/Users/embar/OneDrive/Desktop/Nirvana/Audio Data/DiacWoz/Processed_Chunks\\312_Chunks\n",
      "Loading audio for 319...\n",
      "Finished Participant 319: Created 6 chunks in C:/Users/embar/OneDrive/Desktop/Nirvana/Audio Data/DiacWoz/Processed_Chunks\\319_Chunks\n",
      "Loading audio for 320...\n",
      "Finished Participant 320: Created 7 chunks in C:/Users/embar/OneDrive/Desktop/Nirvana/Audio Data/DiacWoz/Processed_Chunks\\320_Chunks\n",
      "Loading audio for 321...\n",
      "Finished Participant 321: Created 8 chunks in C:/Users/embar/OneDrive/Desktop/Nirvana/Audio Data/DiacWoz/Processed_Chunks\\321_Chunks\n",
      "Loading audio for 325...\n",
      "Finished Participant 325: Created 14 chunks in C:/Users/embar/OneDrive/Desktop/Nirvana/Audio Data/DiacWoz/Processed_Chunks\\325_Chunks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# Use 'r' before the string to handle Windows backslashes correctly\n",
    "BASE_PATH = r'C:/Users/embar/OneDrive/Desktop/Nirvana/Audio Data/DiacWoz/Raw'\n",
    "OUTPUT_BASE = r'C:/Users/embar/OneDrive/Desktop/Nirvana/Audio Data/DiacWoz/Processed_Chunks'\n",
    "\n",
    "CHUNK_DURATION = 35  # Duration in seconds\n",
    "SAMPLE_RATE = 16000  # DAIC-WOZ standard sampling rate\n",
    "\n",
    "# Create output folder if it doesn't exist\n",
    "if not os.path.exists(OUTPUT_BASE):\n",
    "    os.makedirs(OUTPUT_BASE)\n",
    "\n",
    "def process_local_participant(p_id):\n",
    "    p_folder = os.path.join(BASE_PATH, f\"{p_id}_P\")\n",
    "    audio_path = os.path.join(p_folder, f\"{p_id}_AUDIO.wav\")\n",
    "    transcript_path = os.path.join(p_folder, f\"{p_id}_TRANSCRIPT.csv\")\n",
    "\n",
    "    # Check if files exist\n",
    "    if not os.path.exists(audio_path) or not os.path.exists(transcript_path):\n",
    "        print(f\"Skipping {p_id}: Audio or Transcript missing at {p_folder}\")\n",
    "        return\n",
    "\n",
    "    # 1. Load transcript (DAIC uses tab-separated values)\n",
    "    df = pd.read_csv(transcript_path, sep='\\t')\n",
    "    \n",
    "    # 2. Filter for 'Participant' speech only\n",
    "    participant_df = df[df['speaker'] == 'Participant']\n",
    "    \n",
    "    if participant_df.empty:\n",
    "        print(f\"No participant speech found for {p_id}\")\n",
    "        return\n",
    "\n",
    "    # 3. Load raw audio\n",
    "    print(f\"Loading audio for {p_id}...\")\n",
    "    y, sr = librosa.load(audio_path, sr=SAMPLE_RATE)\n",
    "    \n",
    "    # 4. Extract and concatenate only participant voice segments\n",
    "    participant_segments = []\n",
    "    for _, row in participant_df.iterrows():\n",
    "        start_idx = int(row['start_time'] * sr)\n",
    "        stop_idx = int(row['stop_time'] * sr)\n",
    "        segment = y[start_idx:stop_idx]\n",
    "        participant_segments.append(segment)\n",
    "    \n",
    "    full_voice = np.concatenate(participant_segments)\n",
    "\n",
    "    # 5. Break the continuous voice into 35-second chunks\n",
    "    samples_per_chunk = CHUNK_DURATION * sr\n",
    "    num_chunks = len(full_voice) // samples_per_chunk\n",
    "\n",
    "    if num_chunks == 0:\n",
    "        print(f\"Participant {p_id} voice too short for a single {CHUNK_DURATION}s chunk.\")\n",
    "        return\n",
    "\n",
    "    # 6. Save chunks to separate folder for each participant\n",
    "    out_dir = os.path.join(OUTPUT_BASE, f\"{p_id}_Chunks\")\n",
    "    if not os.path.exists(out_dir): \n",
    "        os.makedirs(out_dir)\n",
    "\n",
    "    for i in range(num_chunks):\n",
    "        start = i * samples_per_chunk\n",
    "        end = start + samples_per_chunk\n",
    "        chunk = full_voice[start:end]\n",
    "        \n",
    "        chunk_name = f\"{p_id}_part_{i}.wav\"\n",
    "        save_path = os.path.join(out_dir, chunk_name)\n",
    "        sf.write(save_path, chunk, sr)\n",
    "    \n",
    "    print(f\"Finished Participant {p_id}: Created {num_chunks} chunks in {out_dir}\")\n",
    "\n",
    "# --- EXECUTION ---\n",
    "# List of IDs you have downloaded\n",
    "my_participants = ['303', '304', '305', '310', '312', '319', '320', '321', '325']\n",
    "\n",
    "for pid in my_participants:\n",
    "    try:\n",
    "        process_local_participant(pid)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {pid}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd04957",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "veritasvision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
